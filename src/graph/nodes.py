"""
Nodes - LangGraphì˜ Node í•¨ìˆ˜ë“¤

- llm_node: LLMì—ê²Œ Thought + Actionì„ ê²°ì •í•˜ë„ë¡ ìš”ì²­
- tool_node: Action(Tool í˜¸ì¶œ)ì„ ì‹¤í–‰í•˜ê³  Observation ë°˜í™˜
"""

import os
import json
from typing import Dict, Any, List
from openai import OpenAI
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.graph.state import AgentState
from src.tools.tool_registry import get_tool_specs, execute_tool

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MODEL = "gpt-4o-mini"

# =============================================================================
# System Prompt - ReAct íŒ¨í„´ ê°€ì´ë“œ
# =============================================================================

SYSTEM_PROMPT = """\
You are a helpful AI assistant that uses tools with a ReAct-style loop.

ë‹¹ì‹ ì€ ë‹¤ìŒê³¼ ê°™ì€ Toolë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- search_documents: ìˆ˜ì—… ìë£Œ PDFì—ì„œ ì •ë³´ ê²€ìƒ‰ (Function Calling, RAG, LangGraph ë“±)
- read_memory: ê³¼ê±° ëŒ€í™” ë‚´ìš©ì—ì„œ ê¸°ì–µ ê²€ìƒ‰
- write_memory: ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¥ê¸° ê¸°ì–µì— ì €ì¥
- calculator: ì‚¬ì¹™ì—°ì‚° ìˆ˜í–‰
- get_time: í˜„ì¬ ì‹œê°„ ì¡°íšŒ
- google_search: Google ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹  ì •ë³´ ê²€ìƒ‰

**ReAct íŒ¨í„´ ê°€ì´ë“œ:**

1. **Thought (ìƒê°)**: ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì–´ë–¤ ë„êµ¬ê°€ í•„ìš”í•œì§€ ìƒê°í•©ë‹ˆë‹¤.
2. **Action (í–‰ë™)**: í•„ìš”í•œ ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤ (tool_calls).
3. **Observation (ê´€ì°°)**: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
4. **Final Answer (ìµœì¢… ë‹µë³€)**: ê´€ì°° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.

**ì¤‘ìš” ê·œì¹™:**
- ê°•ì˜ ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ì€ ë°˜ë“œì‹œ `search_documents` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ìµœì‹  ë‰´ìŠ¤, ì‹¤ì‹œê°„ ì •ë³´ëŠ” `google_search` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ê³„ì‚°ì´ í•„ìš”í•˜ë©´ `calculator` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”).
- ì‚¬ìš©ìì˜ ê°œì¸ì •ë³´ë‚˜ ì„ í˜¸ì‚¬í•­ì€ `write_memory`ë¡œ ì €ì¥í•˜ì„¸ìš”.
- ë„êµ¬ ê²°ê³¼ë¥¼ ì§ì ‘ ì¸ìš©í•  ë•ŒëŠ” ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°íˆì„¸ìš”.
- ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

**ë©”ëª¨ë¦¬ ì €ì¥ ê°€ì´ë“œ:**
ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ëŠ” ìë™ìœ¼ë¡œ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤:
- ì‚¬ìš©ìì˜ ì´ë¦„, ì „ê³µ, ê´€ì‹¬ì‚¬ ë“± ê°œì¸ì •ë³´ (memory_type: "profile")
- ì¤‘ìš”í•œ ëŒ€í™” ë‚´ìš©, ì‚¬ê±´, ê²½í—˜ (memory_type: "episodic")
- ì‚¬ìš©ìê°€ í•™ìŠµí•œ ê°œë…, ì´í•´í•œ ë‚´ìš© (memory_type: "knowledge")
"""


# =============================================================================
# Helper: tool_callsë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
# =============================================================================

def convert_tool_calls_to_dict(tool_calls) -> List[Dict]:
    """OpenAI tool_callsë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
    if not tool_calls:
        return None
    
    result = []
    for tc in tool_calls:
        if isinstance(tc, dict):
            # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ë©´ ê·¸ëŒ€ë¡œ
            result.append(tc)
        else:
            # ê°ì²´ë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            result.append({
                "id": getattr(tc, "id", ""),
                "type": "function",
                "function": {
                    "name": getattr(tc.function, "name", ""),
                    "arguments": getattr(tc.function, "arguments", "")
                }
            })
    return result


# =============================================================================
# Helper: ë©”ì‹œì§€ë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
# =============================================================================

def convert_messages_to_openai_format(messages: List) -> List[Dict[str, Any]]:
    """
    LangGraph ë©”ì‹œì§€ë¥¼ OpenAI API í˜•ì‹ìœ¼ë¡œ ë³€í™˜

    Args:
        messages: LangGraphì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ê°ì²´)

    Returns:
        OpenAI API í˜•ì‹ì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    converted = []

    for idx, msg in enumerate(messages):
        # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ë©´ ê²€ì¦ í›„ ì‚¬ìš©
        if isinstance(msg, dict):
            # ë”•ì…”ë„ˆë¦¬ê°€ ì´ë¯¸ ì˜¬ë°”ë¥¸ OpenAI í˜•ì‹ì¸ì§€ í™•ì¸
            # roleì´ ìˆê³ , toolì¸ ê²½ìš° tool_call_idê°€ ìˆì–´ì•¼ í•¨
            if msg.get("role") == "tool":
                # tool ë©”ì‹œì§€ëŠ” tool_call_idì™€ contentê°€ í•„ìˆ˜
                if "tool_call_id" not in msg or "content" not in msg:
                    print(f"âš ï¸ Warning: Incomplete tool message at index {idx}: {msg.get('name', 'unknown')}")
                    # ìŠ¤í‚µí•˜ì§€ ì•Šê³  ê²½ê³ ë§Œ ì¶œë ¥
                # tool ë©”ì‹œì§€ëŠ” ë¬´ì¡°ê±´ ì¶”ê°€ (ìŠ¤í‚µí•˜ë©´ OpenAI API ì—ëŸ¬ ë°œìƒ)
                converted.append(msg)
            else:
                # ë‹¤ë¥¸ ë©”ì‹œì§€ëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€
                converted.append(msg)

        # ê°ì²´ë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        else:
            # LangGraph ë©”ì‹œì§€ íƒ€ì… ë§¤í•‘
            role_map = {
                "human": "user",
                "ai": "assistant",
                "tool": "tool",
                "system": "system"
            }

            msg_type = getattr(msg, "type", "human")
            role = role_map.get(msg_type, "user")

            msg_dict = {
                "role": role,
                "content": getattr(msg, "content", "") or ""
            }

            # tool_callsê°€ ìˆìœ¼ë©´ ì¶”ê°€ (OpenAI í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”)
            tool_calls = getattr(msg, "tool_calls", None)
            if tool_calls:
                openai_tool_calls = []
                for tc in tool_calls:
                    if isinstance(tc, dict):
                        # LangGraph í˜•ì‹: {name, args, id, type: "tool_call"}
                        if "name" in tc and "args" in tc:
                            openai_tool_calls.append({
                                "id": tc.get("id", ""),
                                "type": "function",  # â† OpenAIëŠ” "function"ë§Œ ë°›ìŒ!
                                "function": {
                                    "name": tc["name"],
                                    "arguments": json.dumps(tc["args"], ensure_ascii=False)  # ë‹¤ì‹œ JSON ë¬¸ìì—´ë¡œ
                                }
                            })
                        # ì´ë¯¸ OpenAI í˜•ì‹
                        elif "function" in tc:
                            openai_tool_calls.append(tc)
                    else:
                        # ê°ì²´ í˜•íƒœ
                        openai_tool_calls.append({
                            "id": getattr(tc, "id", ""),
                            "type": "function",
                            "function": {
                                "name": getattr(tc.function, "name", ""),
                                "arguments": getattr(tc.function, "arguments", "")
                            }
                        })

                if openai_tool_calls:
                    msg_dict["tool_calls"] = openai_tool_calls

            # tool ë©”ì‹œì§€ì¸ ê²½ìš° tool_call_id ì¶”ê°€
            if role == "tool":
                if hasattr(msg, "tool_call_id") and msg.tool_call_id:
                    msg_dict["tool_call_id"] = msg.tool_call_id

                # nameë„ ì¶”ê°€
                if hasattr(msg, "name") and msg.name:
                    msg_dict["name"] = msg.name

            converted.append(msg_dict)

    return converted


# =============================================================================
# LLM Node - Thought + Action ê²°ì •
# =============================================================================

def llm_node(state: AgentState) -> Dict[str, Any]:
    """
    LLMì—ê²Œ í˜„ì¬ ìƒíƒœë¥¼ ì „ë‹¬í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ë„ë¡ ìš”ì²­
    
    Returns:
        - messages: LLMì˜ ì‘ë‹µ ë©”ì‹œì§€ (tool_calls í¬í•¨ ê°€ëŠ¥)
        - loop_count: í˜„ì¬ ë£¨í”„ ì¹´ìš´íŠ¸ +1
    """
    messages = state["messages"]
    loop_count = state.get("loop_count", 0)
    
    # ë©”ì‹œì§€ë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    openai_messages = convert_messages_to_openai_format(messages)
    
    # OpenAI API í˜¸ì¶œ
    response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            *openai_messages
        ],
        tools=get_tool_specs(),
        tool_choice="auto"
    )
    
    msg = response.choices[0].message
    
    # ë””ë²„ê¹… ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ¤– LLM Node (ë£¨í”„ {loop_count + 1})")
    print(f"{'='*60}")
    
    if msg.content:
        print(f"ğŸ’­ Thought: {msg.content[:200]}...")
    
    if msg.tool_calls:
        print(f"ğŸ”§ Actions:")
        for tc in msg.tool_calls:
            print(f"   - {tc.function.name}({tc.function.arguments})")
    
    # ë©”ì‹œì§€ êµ¬ì„±
    new_message = {
        "role": "assistant",
        "content": msg.content or "",
    }
    
    if msg.tool_calls:
        # OpenAI tool_callsë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        new_message["tool_calls"] = convert_tool_calls_to_dict(msg.tool_calls)
    
    return {
        "messages": [new_message],
        "loop_count": loop_count + 1
    }


# =============================================================================
# Tool Node - Action ì‹¤í–‰ + Observation
# =============================================================================

def tool_node(state: AgentState) -> Dict[str, Any]:
    """
    LLMì´ ìš”ì²­í•œ Toolì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜
    
    Returns:
        - messages: Tool ì‹¤í–‰ ê²°ê³¼ ë©”ì‹œì§€ë“¤
    """
    messages = state["messages"]
    last_message = messages[-1]
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¨ Tool Node - Executing Actions")
    print(f"{'='*60}")
    
    # last_messageë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    if not isinstance(last_message, dict):
        role_map = {
            "human": "user",
            "ai": "assistant",
            "tool": "tool",
            "system": "system"
        }
        msg_type = getattr(last_message, "type", "ai")
        role = role_map.get(msg_type, "assistant")
        
        last_message = {
            "role": role,
            "content": getattr(last_message, "content", "") or "",
            "tool_calls": convert_tool_calls_to_dict(getattr(last_message, "tool_calls", None))
        }
    
    # tool_callsê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
    tool_calls = last_message.get("tool_calls")
    if not tool_calls:
        print("âš ï¸ Warning: tool_node called but no tool_calls found")
        return {"messages": []}
    
    # ê° Tool ì‹¤í–‰
    tool_messages = []
    
    for tool_call in tool_calls:
        # LangGraph í˜•ì‹ì¸ì§€ OpenAI í˜•ì‹ì¸ì§€ í™•ì¸
        if "name" in tool_call and "args" in tool_call:
            # LangGraph í˜•ì‹: {name, args, id, type}
            tool_name = tool_call["name"]
            arguments = tool_call["args"]  # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬
            tool_call_id = tool_call["id"]
        elif "function" in tool_call:
            # OpenAI í˜•ì‹: {id, type, function: {name, arguments}}
            tool_name = tool_call["function"]["name"]
            arguments = json.loads(tool_call["function"]["arguments"] or "{}")
            tool_call_id = tool_call["id"]
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ - ê°ì²´ë¡œ ê°•ì œ ë³€í™˜ ì‹œë„
            print(f"âš ï¸ Warning: Unknown tool_call format, attempting conversion")
            tool_name = getattr(tool_call.function, "name", "") if hasattr(tool_call, "function") else ""
            arguments = json.loads(getattr(tool_call.function, "arguments", "{}") if hasattr(tool_call, "function") else "{}")
            tool_call_id = getattr(tool_call, "id", "")
        
        print(f"\nğŸ” Executing: {tool_name}")
        print(f"   Arguments: {arguments}")
        
        try:
            # Tool ì‹¤í–‰
            tool_output = execute_tool(tool_name, arguments)
            print(f"   âœ… Success")
            
            # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ í‘œì‹œ)
            preview = tool_output[:200] + "..." if len(tool_output) > 200 else tool_output
            print(f"   ğŸ“Š Result Preview: {preview}")
            
        except Exception as e:
            print(f"   âŒ Error: {str(e)}")
            tool_output = json.dumps({
                "error": f"Tool execution failed: {str(e)}",
                "tool_name": tool_name,
                "arguments": arguments
            }, ensure_ascii=False)
        
        # Tool ë©”ì‹œì§€ ì¶”ê°€
        tool_messages.append({
            "role": "tool",
            "tool_call_id": tool_call_id,
            "name": tool_name,
            "content": tool_output
        })
    
    return {"messages": tool_messages}


# =============================================================================
# Helper: Should Continue ê²°ì • í•¨ìˆ˜
# =============================================================================

def should_continue(state: AgentState) -> str:
    """
    ë‹¤ìŒì— ì–´ë””ë¡œ ê°ˆì§€ ê²°ì •í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        - "tools": Tool ì‹¤í–‰ì´ í•„ìš”í•¨ (tool_callsê°€ ìˆìŒ)
        - "end": ìµœì¢… ë‹µë³€ ì™„ë£Œ (tool_callsê°€ ì—†ìŒ)
    """
    messages = state["messages"]
    last_message = messages[-1]
    loop_count = state.get("loop_count", 0)
    
    # ë¬´í•œ ë£¨í”„ ë°©ì§€ (ìµœëŒ€ 10ë²ˆ)
    MAX_LOOPS = 10
    if loop_count >= MAX_LOOPS:
        print(f"\nâš ï¸ Max loops ({MAX_LOOPS}) reached. Forcing end.")
        return "end"
    
    # last_messageë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    if not isinstance(last_message, dict):
        role_map = {
            "human": "user",
            "ai": "assistant",
            "tool": "tool",
            "system": "system"
        }
        msg_type = getattr(last_message, "type", "ai")
        role = role_map.get(msg_type, "assistant")
        
        last_message = {
            "role": role,
            "content": getattr(last_message, "content", "") or "",
            "tool_calls": convert_tool_calls_to_dict(getattr(last_message, "tool_calls", None))
        }
    
    # tool_callsê°€ ìˆìœ¼ë©´ Tool Nodeë¡œ
    if last_message.get("tool_calls"):
        return "tools"
    
    # ì—†ìœ¼ë©´ ì¢…ë£Œ
    return "end"