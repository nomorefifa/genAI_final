"""
Memory Reflection - ëŒ€í™” ì¤‘ ì¤‘ìš” ì •ë³´ ìë™ ì €ì¥

ì´ ëª¨ë“ˆì€:
1. ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ ì¶”ì¶œ
2. ìë™ìœ¼ë¡œ write_memoryë¥¼ í˜¸ì¶œí•˜ì—¬ ì¥ê¸° ê¸°ì–µì— ì €ì¥
3. ì‚¬ìš©ìì—ê²Œ ë°©í•´ë˜ì§€ ì•Šê²Œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‘ë™
"""

import os
from typing import List, Dict, Any, Optional
from openai import OpenAI
import json
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.tools.memory_tool import write_memory

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MODEL = "gpt-4o-mini"


# =============================================================================
# Memory Extractor Prompt
# =============================================================================

MEMORY_EXTRACTOR_PROMPT = """\
ë‹¹ì‹ ì€ ëŒ€í™”ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¥ê¸° ê¸°ì–µì— ì €ì¥í•˜ëŠ” AIì…ë‹ˆë‹¤.

ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì €ì¥í•  ê°€ì¹˜ê°€ ìˆëŠ” ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

**ì €ì¥í•´ì•¼ í•  ì •ë³´ ìœ í˜•:**

1. **Profile (ê°œì¸ì •ë³´)** - memory_type: "profile"
   - ì‚¬ìš©ìì˜ ì´ë¦„, ë‚˜ì´, ì§ì—…, ì „ê³µ
   - ê±°ì£¼ì§€, ê°€ì¡± ê´€ê³„
   - ì—°ë½ì²˜, ì´ë©”ì¼ ë“±
   ì˜ˆì‹œ: "ì‚¬ìš©ì ì´ë¦„ì€ ê¹€ì² ìˆ˜, ì»´í“¨í„°ê³µí•™ê³¼ 3í•™ë…„"

2. **Episodic (ëŒ€í™”/ì‚¬ê±´)** - memory_type: "episodic"
   - ì¤‘ìš”í•œ ëŒ€í™” ë‚´ìš©, ê²°ì •ì‚¬í•­
   - íŠ¹ì • ë‚ ì§œì˜ ì‚¬ê±´ì´ë‚˜ ê²½í—˜
   - ì‚¬ìš©ìì˜ ì˜ê²¬, ê°ì • í‘œí˜„
   ì˜ˆì‹œ: "ì‚¬ìš©ìê°€ LangGraphë¥¼ ì²˜ìŒ í•™ìŠµí•¨ (2024-11-27)"

3. **Knowledge (í•™ìŠµ/ì§€ì‹)** - memory_type: "knowledge"
   - ì‚¬ìš©ìê°€ ë°°ìš´ ê°œë…ì´ë‚˜ ì´í•´í•œ ë‚´ìš©
   - í•™ìŠµ ì§„ë„, ì™„ë£Œí•œ ê³¼ì œ
   - ê´€ì‹¬ ìˆëŠ” ì£¼ì œë‚˜ ê¸°ìˆ 
   ì˜ˆì‹œ: "ReAct íŒ¨í„´: Thought-Action-Observation ìˆœì„œë¡œ ì‘ë™í•˜ëŠ” AI Agent ë°©ë²•ë¡ "

**ì¤‘ìš”ë„ íŒë‹¨ ê¸°ì¤€:**
- 5: ë§¤ìš° ì¤‘ìš”í•œ ì •ë³´ (ì´ë¦„, ì „ê³µ, ì¤‘ìš”í•œ ê²°ì •ì‚¬í•­, ì¥ê¸° ëª©í‘œ)
- 4: ì¤‘ìš”í•œ ì •ë³´ (í•™ìŠµ ë‚´ìš©, ì„ í˜¸ì‚¬í•­, í”„ë¡œì íŠ¸ ì •ë³´)
- 3: ë³´í†µ ì •ë³´ (ì¼ë°˜ì ì¸ ëŒ€í™” ë‚´ìš©)
- 2: ì•½ê°„ ì¤‘ìš”í•œ ì •ë³´ (ì°¸ê³ ìš© ì •ë³´)
- 1: ë‚®ì€ ì¤‘ìš”ë„ (ë‹¨ìˆœí•œ ëŒ€í™”)

**ì¶œë ¥ í˜•ì‹:**
JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”. ì €ì¥í•  ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”.

[
  {
    "content": "ì €ì¥í•  ë‚´ìš©",
    "memory_type": "profile | episodic | knowledge",
    "importance": 1~5 (ì •ìˆ˜)
  },
  ...
]

**ì¤‘ìš”:** 
- ì €ì¥í•  ë§Œí•œ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”.
- ë‹¨ìˆœí•œ ì¸ì‚¬ë§ì´ë‚˜ ì§ˆë¬¸ë§Œ ìˆëŠ” ê²½ìš° ì €ì¥í•˜ì§€ ë§ˆì„¸ìš”.
- ì´ë¯¸ ì•Œê³  ìˆëŠ” ì¼ë°˜ ìƒì‹ì€ ì €ì¥í•˜ì§€ ë§ˆì„¸ìš”.
"""


# =============================================================================
# Memory Extraction Function
# =============================================================================

def extract_memories_from_conversation(
    messages: List[Dict[str, Any]],
    min_importance: int = 3
) -> List[Dict[str, str]]:
    """
    ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì €ì¥í•  ì •ë³´ ì¶”ì¶œ

    Args:
        messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        min_importance: ìµœì†Œ ì¤‘ìš”ë„ (1-5, ê¸°ë³¸ê°’ 3)

    Returns:
        ì €ì¥í•  ë©”ëª¨ë¦¬ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    
    # ëŒ€í™” ë‚´ìš© í¬ë§·íŒ…
    conversation_text = ""
    for msg in messages:
        role = msg.get("role", "unknown")
        
        if role == "user":
            content = msg.get("content", "")
            conversation_text += f"User: {content}\n\n"
        
        elif role == "assistant":
            content = msg.get("content", "")
            if content:  # ë¹ˆ contentëŠ” ìŠ¤í‚µ
                conversation_text += f"Assistant: {content}\n\n"
    
    if not conversation_text.strip():
        return []
    
    # LLMì—ê²Œ ë©”ëª¨ë¦¬ ì¶”ì¶œ ìš”ì²­
    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": MEMORY_EXTRACTOR_PROMPT},
                {"role": "user", "content": conversation_text}
            ],
            temperature=0.3
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹±
        # ê°€ë” LLMì´ ```json ``` ê°™ì€ ë§ˆí¬ë‹¤ìš´ì„ ë¶™ì´ëŠ” ê²½ìš° ì œê±°
        result_text = result_text.replace("```json", "").replace("```", "").strip()
        
        memories = json.loads(result_text)

        # ì¤‘ìš”ë„ í•„í„°ë§ (1-5 ì •ìˆ˜ ê¸°ì¤€)
        filtered_memories = [
            m for m in memories
            if m.get("importance", 1) >= min_importance
        ]

        return filtered_memories
    
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSON íŒŒì‹± ì—ëŸ¬: {e}")
        print(f"   Response: {result_text[:200]}")
        return []
    
    except Exception as e:
        print(f"âš ï¸ Memory ì¶”ì¶œ ì—ëŸ¬: {e}")
        return []


# =============================================================================
# Auto Save Function
# =============================================================================

def auto_save_memories(
    messages: List[Dict[str, Any]],
    min_importance: int = 3,
    verbose: bool = True
) -> int:
    """
    ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì €ì¥

    Args:
        messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        min_importance: ìµœì†Œ ì¤‘ìš”ë„ (1-5, ê¸°ë³¸ê°’ 3)
        verbose: ì €ì¥ ê³¼ì • ì¶œë ¥ ì—¬ë¶€

    Returns:
        ì €ì¥ëœ ë©”ëª¨ë¦¬ ê°œìˆ˜
    """
    
    # 1. ë©”ëª¨ë¦¬ ì¶”ì¶œ
    memories = extract_memories_from_conversation(messages, min_importance)
    
    if not memories:
        if verbose:
            print("\nğŸ’¾ Auto-save: ì €ì¥í•  ë©”ëª¨ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0
    
    # 2. ê° ë©”ëª¨ë¦¬ ì €ì¥
    saved_count = 0
    
    if verbose:
        print(f"\nğŸ’¾ Auto-save: {len(memories)}ê°œì˜ ë©”ëª¨ë¦¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤...")
    
    for mem in memories:
        content = mem.get("content", "")
        memory_type = mem.get("memory_type", "episodic")
        importance = mem.get("importance", "medium")
        
        try:
            result = write_memory(content, memory_type, importance)
            
            if verbose:
                print(f"   âœ… [{memory_type}] {content[:50]}...")
            
            saved_count += 1
        
        except Exception as e:
            if verbose:
                print(f"   âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    if verbose:
        print(f"ğŸ’¾ ì´ {saved_count}ê°œ ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ!\n")
    
    return saved_count


# =============================================================================
# Helper: ë§ˆì§€ë§‰ Nê°œ ë©”ì‹œì§€ë§Œ ë¶„ì„
# =============================================================================

def auto_save_recent_memories(
    messages: List[Dict[str, Any]],
    recent_n: int = 10,
    min_importance: int = 3,
    verbose: bool = True
) -> int:
    """
    ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ë¶„ì„í•˜ì—¬ ë©”ëª¨ë¦¬ ì €ì¥
    (ê¸´ ëŒ€í™”ì—ì„œ ë§¤ë²ˆ ì „ì²´ ë¶„ì„í•˜ë©´ ë¹„íš¨ìœ¨ì )

    Args:
        messages: ì „ì²´ ëŒ€í™” ë©”ì‹œì§€
        recent_n: ë¶„ì„í•  ìµœê·¼ ë©”ì‹œì§€ ê°œìˆ˜
        min_importance: ìµœì†Œ ì¤‘ìš”ë„ (1-5, ê¸°ë³¸ê°’ 3)
        verbose: ì¶œë ¥ ì—¬ë¶€

    Returns:
        ì €ì¥ëœ ë©”ëª¨ë¦¬ ê°œìˆ˜
    """
    recent_messages = messages[-recent_n:] if len(messages) > recent_n else messages
    return auto_save_memories(recent_messages, min_importance, verbose)


# =============================================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# =============================================================================

if __name__ == "__main__":
    print("ğŸ§ª Memory Reflection í…ŒìŠ¤íŠ¸\n")
    
    # í…ŒìŠ¤íŠ¸ ëŒ€í™”
    test_conversation = [
        {"role": "user", "content": "ì•ˆë…•! ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì•¼. ì»´í“¨í„°ê³µí•™ê³¼ 3í•™ë…„ì´ì•¼."},
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš” ê¹€ì² ìˆ˜ë‹˜! ì»´í“¨í„°ê³µí•™ê³¼ 3í•™ë…„ì´ì‹œêµ°ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"},
        {"role": "user", "content": "LangGraphì— ëŒ€í•´ ë°°ìš°ê³  ì‹¶ì–´. ReAct íŒ¨í„´ì´ ë­”ì§€ ì„¤ëª…í•´ì¤„ë˜?"},
        {"role": "assistant", "content": "ReAct íŒ¨í„´ì€ Thought(ìƒê°) - Action(í–‰ë™) - Observation(ê´€ì°°) ìˆœì„œë¡œ ì‘ë™í•˜ëŠ” AI Agent ë°©ë²•ë¡ ì…ë‹ˆë‹¤. LangGraphëŠ” ì´ëŸ¬í•œ íŒ¨í„´ì„ StateGraphë¡œ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤."},
        {"role": "user", "content": "ì•„ ì´í•´í–ˆì–´! ì´ê±° ê¸°ë§ í”„ë¡œì íŠ¸ ì£¼ì œë¡œ ì •í–ˆì–´."},
        {"role": "assistant", "content": "ì¢‹ì€ ì„ íƒì…ë‹ˆë‹¤! LangGraph ReAct AgentëŠ” í›Œë¥­í•œ ê¸°ë§ í”„ë¡œì íŠ¸ ì£¼ì œì…ë‹ˆë‹¤."}
    ]
    
    print("ğŸ“ í…ŒìŠ¤íŠ¸ ëŒ€í™”:")
    print("-" * 60)
    for msg in test_conversation:
        role = msg["role"]
        content = msg["content"]
        print(f"{role.upper()}: {content}")
    print("-" * 60)
    
    # ë©”ëª¨ë¦¬ ìë™ ì €ì¥ í…ŒìŠ¤íŠ¸
    saved_count = auto_save_memories(test_conversation, min_importance=1)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! {saved_count}ê°œ ë©”ëª¨ë¦¬ ì €ì¥ë¨")