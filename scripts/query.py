import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

import chromadb
from src.rag.utils import embed_texts, build_prompt, chat_with_openai

# ì„¤ì •
CHROMA_DIR = "chroma_db"
COLLECTION_NAME = "documents"

def search_documents(query: str, n_results: int = 5):
    """ChromaDBì—ì„œ ë¬¸ì„œ ê²€ìƒ‰"""
    # ChromaDB ì—°ê²°
    client = chromadb.PersistentClient(path=CHROMA_DIR)
    collection = client.get_collection(name=COLLECTION_NAME)
    
    # ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = embed_texts([query])[0]
    
    # ê²€ìƒ‰
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=n_results
    )
    
    return results

def main():
    print("\n" + "="*50)
    print("RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("="*50 + "\n")
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "LangGraph State ì„¤ê³„ ë°©ë²•",
        "ReAct íŒ¨í„´ì´ë€?",
        "HNSW ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…",
        "Memory ì‹œìŠ¤í…œ êµ¬ì„±ìš”ì†Œ"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n[í…ŒìŠ¤íŠ¸ {i}] ì§ˆë¬¸: {query}")
        print("-" * 50)
        
        # ê²€ìƒ‰
        results = search_documents(query, n_results=3)
        
        # ê²°ê³¼ ì¶œë ¥
        if results['documents'] and results['documents'][0]:
            print(f"âœ… ê²€ìƒ‰ ì„±ê³µ! {len(results['documents'][0])}ê°œ ê²°ê³¼ ë°œê²¬\n")
            
            for j, (doc, metadata, distance) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            ), 1):
                source = os.path.basename(metadata.get('source', 'unknown'))
                chunk_id = metadata.get('chunk_id', '?')
                print(f"  [{j}] {source} (ì²­í¬ {chunk_id}) - ìœ ì‚¬ë„: {1-distance:.3f}")
                print(f"      ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc[:100]}...")
                print()
        else:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
    
    print("\n" + "="*50)
    print("ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*50)
    
    # ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ
    print("\nğŸ’¬ ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')")
    print("-" * 50)
    
    while True:
        user_query = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if user_query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("ğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if not user_query:
            continue
        
        # ê²€ìƒ‰
        results = search_documents(user_query, n_results=5)
        
        if results['documents'] and results['documents'][0]:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            contexts = []
            for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
                contexts.append({
                    'text': doc,
                    'source': metadata.get('source', 'unknown'),
                    'chunk_id': metadata.get('chunk_id', 0)
                })
            
            # LLMì—ê²Œ ì§ˆë¬¸
            messages = build_prompt(user_query, contexts)
            answer = chat_with_openai(messages)
            
            print("\nğŸ¤– ë‹µë³€:")
            print("-" * 50)
            print(answer)
        else:
            print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()